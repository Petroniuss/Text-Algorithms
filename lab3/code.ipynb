{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from static_huff import static_huffman\n",
    "from adaptive_huff import adaptive_huffman\n",
    "from bitarray import bitarray\n",
    "\n",
    "import static_huff\n",
    "import adaptive_huff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Static Huffman Showcase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "-----HUFFMAN TREE-----\n#11\n 0 -> #5 => a\n 1 -> #6\n  0 -> #2\n   0 -> #1 => c\n   1 -> #1 => d\n  1 -> #4\n   0 -> #2 => r\n   1 -> #2 => b"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "static_huffman(\"abracadabra\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "abracadabra\n"
    }
   ],
   "source": [
    "text = \"abracadabra\"\n",
    "encoded, root = static_huff.encode(text)\n",
    "decoded = static_huff.decode(encoded, root)\n",
    "\n",
    "print(decoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adaptive huffman showcase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "-----HUFFMAN TREE-----\n#{ W=11, N=11 }\n 0 -> #{ W=5, N=9 } => a\n 1 -> #{ W=6, N=10 }\n  0 -> #{ W=2, N=7 }\n   0 -> #{ W=1, N=3 }\n    0 -> #{ W=0, N=1 } => NYT\n    1 -> #{ W=1, N=2 } => d\n   1 -> #{ W=1, N=4 } => c\n  1 -> #{ W=4, N=8 }\n   0 -> #{ W=2, N=5 } => r\n   1 -> #{ W=2, N=6 } => b"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "adaptive_huff.adaptive_huffman(text, N = 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "abracadabra\n"
    }
   ],
   "source": [
    "bits = adaptive_huff.encode(text)\n",
    "decoded = adaptive_huff.decode(bits)\n",
    "\n",
    "print(decoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating test files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import random\n",
    "import os\n",
    "import timeit\n",
    "import pandas as pd\n",
    "\n",
    "def get_size(path):\n",
    "    return os.path.getsize(path) / (2 ** 10)\n",
    "\n",
    "def rand_char():\n",
    "    return random.choice(string.ascii_lowercase)\n",
    "\n",
    "def generate_txt_file(filename, size):\n",
    "    characters = size\n",
    "    characters_per_line = 100\n",
    "    with open(filename, \"w\", encoding = 'ascii') as file:\n",
    "        counter = 1\n",
    "        while counter < (characters - 1):\n",
    "            line = ''\n",
    "            while ((counter % characters_per_line) != 0) and counter < (characters - 1):\n",
    "                counter += 1\n",
    "                line += rand_char()    \n",
    "\n",
    "            line += '\\n'\n",
    "            counter += 1\n",
    "            file.write(line)\n",
    "\n",
    "\n",
    "test_files = ['./resources/file1.txt', './resources/file2.txt', './resources/file3.txt', './resources/file4.txt']\n",
    "\n",
    "compress_to_static_huff = ['./resources/file1.shf', './resources/file2.shf', './resources/file3.shf', './resources/file4.shf']\n",
    "\n",
    "decompress_to_static_huff = ['./resources/file1_shf.txt', './resources/file2_shf.txt', './resources/file3_shf.txt', './resources/file4_shf.txt']\n",
    "\n",
    "compress_to_adaptive_huff = ['./resources/file1.ahf', './resources/file2.ahf', './resources/file3.ahf', './resources/file4.ahf']\n",
    "\n",
    "decompress_to_adaptive_huff = ['./resources/file1_ahf.txt', './resources/file2_ahf.txt', './resources/file3_ahf.txt', './resources/file4_ahf.txt']\n",
    "\n",
    "for i, file in enumerate(test_files):\n",
    "    generate_txt_file(file, (2 ** 10) * (10 ** i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code for test suites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_suite_static_huffman():\n",
    "    columns = ['Size [kB]', 'Compression Time [s]', 'Compressed Size [kB]', 'Compression Rate [%]', 'Decompression Time [s]']\n",
    "    df = pd.DataFrame(columns = columns)\n",
    "    for i in range(4):\n",
    "        row = test_static_huff(i, columns)\n",
    "        df = df.append(row, ignore_index = False)\n",
    "\n",
    "    return df\n",
    "\n",
    "def test_static_huff(i, columns):\n",
    "    in_file = test_files[i]\n",
    "    in_file_size = get_size(in_file)\n",
    "\n",
    "    compress_to = compress_to_static_huff[i]\n",
    "    decompress_to = decompress_to_static_huff[i]\n",
    "\n",
    "    def compress_closure():\n",
    "        return static_huff.compress_file(in_file, compress_to)\n",
    "    \n",
    "    compr_time = timeit.timeit(compress_closure, number=1)\n",
    "    compr_size = get_size(compress_to)\n",
    "    compr_rate = (compr_size / in_file_size) * 100\n",
    "\n",
    "    def decompress_closure():\n",
    "        return static_huff.decompress_file(compress_to, decompress_to)\n",
    "\n",
    "    decompr_time = timeit.timeit(decompress_closure, number=1)\n",
    "\n",
    "    data = {\n",
    "        columns[0]: in_file_size,\n",
    "        columns[1]: compr_time,\n",
    "        columns[2]: compr_size,\n",
    "        columns[3]: compr_rate,\n",
    "        columns[4]: decompr_time\n",
    "    }\n",
    "    \n",
    "    return pd.Series(data = data, name = '\\u2713')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_suite_adaptive_huffman():\n",
    "    columns = ['Size [kB]', 'Compression Time [s]', 'Compressed Size [kB]', 'Compression Rate [%]', 'Decompression Time [s]']\n",
    "    df = pd.DataFrame(columns = columns)\n",
    "    for i in range(4):\n",
    "        row = test_adaptive_huff(i, columns)\n",
    "        df = df.append(row, ignore_index = False)\n",
    "\n",
    "    return df\n",
    "\n",
    "def test_adaptive_huff(i, columns):\n",
    "    in_file = test_files[i]\n",
    "    in_file_size = get_size(in_file)\n",
    "\n",
    "    compress_to = compress_to_adaptive_huff[i]\n",
    "    decompress_to = decompress_to_adaptive_huff[i]\n",
    "\n",
    "    def compress_closure():\n",
    "        return adaptive_huff.compress_file(in_file, compress_to)\n",
    "    \n",
    "    compr_time = timeit.timeit(compress_closure, number=1)\n",
    "    compr_size = get_size(compress_to)\n",
    "    compr_rate = (compr_size / in_file_size) * 100\n",
    "\n",
    "    def decompress_closure():\n",
    "        return adaptive_huff.decompress_file(compress_to, decompress_to)\n",
    "\n",
    "    decompr_time = timeit.timeit(decompress_closure, number=1)\n",
    "\n",
    "    data = {\n",
    "        columns[0]: in_file_size,\n",
    "        columns[1]: compr_time,\n",
    "        columns[2]: compr_size,\n",
    "        columns[3]: compr_rate,\n",
    "        columns[4]: decompr_time\n",
    "    }\n",
    "    \n",
    "    return pd.Series(data = data, name = '\\u2713')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observations & Notes\n",
    "    - Binary file format descriptions are in source files. I figured it will make more sense with code beneath.\n",
    "    - Difference in compression rate for static huffman test between 1kB and more\n",
    "      comes from somewhat inefficient binary format (which comes from the fact that\n",
    "      python allows us to write (one or more) byte chunks to file - of course there is a way to go around it, but I did not want to clutter implementation) for code table.\n",
    "      This cost becomes negligable when actual encoding becomes bigger (files with sizes grater than 1kB).\n",
    "    - We can see that compression rate approaches a limit of roughly 59% when files get bigger.\n",
    "    - When input file contains characters with similar distribution (which is the case because I generated file by choosing random characters from alphabet),\n",
    "      adaptive huffman requires a lot of swapping which adds a lot of overhead and as result running time is quite substantial.\n",
    "      It would seem as reading a file twice is not that big problem. But there are other situation where such compression might be useful e.g live streaming.\n",
    "    - We would expect that adaptive huffman's compression rate will be higher (because we do not have information about overall frequencies), but again\n",
    "      because characters have roughly the same distribution, both static and adaptive apporach the same compressionn rate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "     Size [kB]  Compression Time [s]  Compressed Size [kB]  \\\nâœ“     1.009766              0.015093              0.680664   \nâœ“    10.099609              0.016032              6.084961   \nâœ“   100.999023              0.057797             60.153320   \nâœ“  1009.999023              0.346723            601.146484   \n\n   Compression Rate [%]  Decompression Time [s]  \nâœ“             67.408124                0.013746  \nâœ“             60.249468                0.033462  \nâœ“             59.558319                0.202704  \nâœ“             59.519511                1.658021  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Size [kB]</th>\n      <th>Compression Time [s]</th>\n      <th>Compressed Size [kB]</th>\n      <th>Compression Rate [%]</th>\n      <th>Decompression Time [s]</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>âœ“</th>\n      <td>1.009766</td>\n      <td>0.015093</td>\n      <td>0.680664</td>\n      <td>67.408124</td>\n      <td>0.013746</td>\n    </tr>\n    <tr>\n      <th>âœ“</th>\n      <td>10.099609</td>\n      <td>0.016032</td>\n      <td>6.084961</td>\n      <td>60.249468</td>\n      <td>0.033462</td>\n    </tr>\n    <tr>\n      <th>âœ“</th>\n      <td>100.999023</td>\n      <td>0.057797</td>\n      <td>60.153320</td>\n      <td>59.558319</td>\n      <td>0.202704</td>\n    </tr>\n    <tr>\n      <th>âœ“</th>\n      <td>1009.999023</td>\n      <td>0.346723</td>\n      <td>601.146484</td>\n      <td>59.519511</td>\n      <td>1.658021</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 40
    }
   ],
   "source": [
    "test_suite_static_huffman()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "     Size [kB]  Compression Time [s]  Compressed Size [kB]  \\\nâœ“     1.009766              0.013316              0.634766   \nâœ“    10.099609              0.149527              6.067383   \nâœ“   100.999023              1.003829             60.637695   \nâœ“  1009.999023             10.506341            602.500977   \n\n   Compression Rate [%]  Decompression Time [s]  \nâœ“             62.862669                0.027310  \nâœ“             60.075421                0.122545  \nâœ“             60.037903                1.124813  \nâœ“             59.653620               11.225053  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Size [kB]</th>\n      <th>Compression Time [s]</th>\n      <th>Compressed Size [kB]</th>\n      <th>Compression Rate [%]</th>\n      <th>Decompression Time [s]</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>âœ“</th>\n      <td>1.009766</td>\n      <td>0.013316</td>\n      <td>0.634766</td>\n      <td>62.862669</td>\n      <td>0.027310</td>\n    </tr>\n    <tr>\n      <th>âœ“</th>\n      <td>10.099609</td>\n      <td>0.149527</td>\n      <td>6.067383</td>\n      <td>60.075421</td>\n      <td>0.122545</td>\n    </tr>\n    <tr>\n      <th>âœ“</th>\n      <td>100.999023</td>\n      <td>1.003829</td>\n      <td>60.637695</td>\n      <td>60.037903</td>\n      <td>1.124813</td>\n    </tr>\n    <tr>\n      <th>âœ“</th>\n      <td>1009.999023</td>\n      <td>10.506341</td>\n      <td>602.500977</td>\n      <td>59.653620</td>\n      <td>11.225053</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 41
    }
   ],
   "source": [
    "test_suite_adaptive_huffman()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}